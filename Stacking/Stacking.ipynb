{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS508-Assignment6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf-p0-lGBUI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95de6e5b-6f78-4c2c-fca7-52e2b1233f68"
      },
      "source": [
        "#Import Python Packages\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive/')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVG9hqkMISEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc5c022-4f1e-444c-e287-3b446fb17e16"
      },
      "source": [
        "#Import all necessary library\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "get_ipython().system('pip install vecstack')\n",
        "from collections import Counter #for Smote, \n",
        "import warnings\n",
        "from vecstack import stacking\n",
        "\n",
        "from sklearn.metrics import accuracy_score #works\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vecstack in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from vecstack) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->vecstack) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWybsWyZIv0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "5302a1b7-0581-4e48-c1d4-ce816986d4b5"
      },
      "source": [
        "#Read training data file\n",
        "trainfile = r'/gdrive/My Drive/Churn-Train-2.csv'\n",
        "trainData = pd.read_csv(trainfile)\n",
        "\n",
        "#Read test data file\n",
        "testfile = r'/gdrive/My Drive/Churn-Test-2.csv'\n",
        "testData = pd.read_csv(testfile)\n",
        "\n",
        "trainData.head()\n",
        "#print(\"=======\")\n",
        "testData.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Account Length</th>\n",
              "      <th>Area Code</th>\n",
              "      <th>Int'l Plan</th>\n",
              "      <th>VMail Plan</th>\n",
              "      <th>VMail Message</th>\n",
              "      <th>Day Mins</th>\n",
              "      <th>Day Calls</th>\n",
              "      <th>Day Charge</th>\n",
              "      <th>Eve Mins</th>\n",
              "      <th>Eve Calls</th>\n",
              "      <th>Eve Charge</th>\n",
              "      <th>Night Mins</th>\n",
              "      <th>Night Calls</th>\n",
              "      <th>Night Charge</th>\n",
              "      <th>Intl Mins</th>\n",
              "      <th>Intl Calls</th>\n",
              "      <th>Intl Charge</th>\n",
              "      <th>CustServ Calls</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VT</td>\n",
              "      <td>50</td>\n",
              "      <td>415</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>26</td>\n",
              "      <td>307.1</td>\n",
              "      <td>94</td>\n",
              "      <td>52.21</td>\n",
              "      <td>289.4</td>\n",
              "      <td>78</td>\n",
              "      <td>24.60</td>\n",
              "      <td>174.9</td>\n",
              "      <td>109</td>\n",
              "      <td>7.87</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UT</td>\n",
              "      <td>72</td>\n",
              "      <td>415</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>118.2</td>\n",
              "      <td>106</td>\n",
              "      <td>20.09</td>\n",
              "      <td>167.2</td>\n",
              "      <td>136</td>\n",
              "      <td>14.21</td>\n",
              "      <td>214.2</td>\n",
              "      <td>106</td>\n",
              "      <td>9.64</td>\n",
              "      <td>12.2</td>\n",
              "      <td>3</td>\n",
              "      <td>3.29</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KS</td>\n",
              "      <td>130</td>\n",
              "      <td>510</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>95</td>\n",
              "      <td>26.18</td>\n",
              "      <td>205.9</td>\n",
              "      <td>106</td>\n",
              "      <td>17.50</td>\n",
              "      <td>233.7</td>\n",
              "      <td>75</td>\n",
              "      <td>10.52</td>\n",
              "      <td>12.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3.48</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NV</td>\n",
              "      <td>143</td>\n",
              "      <td>408</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>155.5</td>\n",
              "      <td>101</td>\n",
              "      <td>26.44</td>\n",
              "      <td>213.4</td>\n",
              "      <td>89</td>\n",
              "      <td>18.14</td>\n",
              "      <td>237.9</td>\n",
              "      <td>61</td>\n",
              "      <td>10.71</td>\n",
              "      <td>7.6</td>\n",
              "      <td>11</td>\n",
              "      <td>2.05</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DE</td>\n",
              "      <td>89</td>\n",
              "      <td>510</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>125.6</td>\n",
              "      <td>108</td>\n",
              "      <td>21.35</td>\n",
              "      <td>213.0</td>\n",
              "      <td>90</td>\n",
              "      <td>18.11</td>\n",
              "      <td>181.7</td>\n",
              "      <td>108</td>\n",
              "      <td>8.18</td>\n",
              "      <td>5.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1.46</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  State  Account Length  Area Code  ... Intl Charge CustServ Calls  TARGET\n",
              "0    VT              50        415  ...        2.16              0       0\n",
              "1    UT              72        415  ...        3.29              3       0\n",
              "2    KS             130        510  ...        3.48              1       0\n",
              "3    NV             143        408  ...        2.05              1       0\n",
              "4    DE              89        510  ...        1.46              1       0\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQeY43Swrc_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da180d35-7426-4ca2-dc08-76c2f43e3cce"
      },
      "source": [
        "print(trainData.shape)      # To get (Number of Rows, Number of Columns) of a data frame we use DataFrame.shape \n",
        "print(testData.shape)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1165, 20)\n",
            "(1261, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFGRLe8ArkQc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "9521bf29-e2ce-4b8e-a337-2318895f7a19"
      },
      "source": [
        "# To check basic statistics of a data set, column wise\n",
        "trainData.describe()\n",
        "\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Account Length</th>\n",
              "      <th>Area Code</th>\n",
              "      <th>VMail Message</th>\n",
              "      <th>Day Mins</th>\n",
              "      <th>Day Calls</th>\n",
              "      <th>Day Charge</th>\n",
              "      <th>Eve Mins</th>\n",
              "      <th>Eve Calls</th>\n",
              "      <th>Eve Charge</th>\n",
              "      <th>Night Mins</th>\n",
              "      <th>Night Calls</th>\n",
              "      <th>Night Charge</th>\n",
              "      <th>Intl Mins</th>\n",
              "      <th>Intl Calls</th>\n",
              "      <th>Intl Charge</th>\n",
              "      <th>CustServ Calls</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>1165.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>100.107296</td>\n",
              "      <td>437.899571</td>\n",
              "      <td>8.319313</td>\n",
              "      <td>181.588412</td>\n",
              "      <td>100.605150</td>\n",
              "      <td>30.870532</td>\n",
              "      <td>199.351073</td>\n",
              "      <td>99.871245</td>\n",
              "      <td>16.945021</td>\n",
              "      <td>199.931159</td>\n",
              "      <td>100.104721</td>\n",
              "      <td>8.996927</td>\n",
              "      <td>10.228155</td>\n",
              "      <td>4.550215</td>\n",
              "      <td>2.762172</td>\n",
              "      <td>1.539056</td>\n",
              "      <td>0.125322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>40.128933</td>\n",
              "      <td>42.861654</td>\n",
              "      <td>13.730382</td>\n",
              "      <td>54.392831</td>\n",
              "      <td>19.819381</td>\n",
              "      <td>9.246717</td>\n",
              "      <td>52.633766</td>\n",
              "      <td>20.077314</td>\n",
              "      <td>4.473876</td>\n",
              "      <td>51.233628</td>\n",
              "      <td>19.899559</td>\n",
              "      <td>2.305449</td>\n",
              "      <td>2.833913</td>\n",
              "      <td>2.538757</td>\n",
              "      <td>0.765126</td>\n",
              "      <td>1.307352</td>\n",
              "      <td>0.331226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>408.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>2.130000</td>\n",
              "      <td>31.200000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.650000</td>\n",
              "      <td>43.700000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.970000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>73.000000</td>\n",
              "      <td>408.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>146.800000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>24.960000</td>\n",
              "      <td>164.400000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>13.970000</td>\n",
              "      <td>167.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>7.520000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.270000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>98.000000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>182.300000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>30.990000</td>\n",
              "      <td>200.200000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>17.020000</td>\n",
              "      <td>200.500000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>9.020000</td>\n",
              "      <td>10.300000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>128.000000</td>\n",
              "      <td>510.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>36.720000</td>\n",
              "      <td>234.100000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>19.900000</td>\n",
              "      <td>236.600000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>10.650000</td>\n",
              "      <td>12.100000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.270000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>243.000000</td>\n",
              "      <td>510.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>350.800000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>59.640000</td>\n",
              "      <td>351.600000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>29.890000</td>\n",
              "      <td>364.300000</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>16.390000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Account Length    Area Code  ...  CustServ Calls       TARGET\n",
              "count     1165.000000  1165.000000  ...     1165.000000  1165.000000\n",
              "mean       100.107296   437.899571  ...        1.539056     0.125322\n",
              "std         40.128933    42.861654  ...        1.307352     0.331226\n",
              "min          1.000000   408.000000  ...        0.000000     0.000000\n",
              "25%         73.000000   408.000000  ...        1.000000     0.000000\n",
              "50%         98.000000   415.000000  ...        1.000000     0.000000\n",
              "75%        128.000000   510.000000  ...        2.000000     0.000000\n",
              "max        243.000000   510.000000  ...        9.000000     1.000000\n",
              "\n",
              "[8 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaxGWndzrkTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33eb96cd-b042-44cc-d27c-911618c8e44e"
      },
      "source": [
        "#To get list of names of all Columns from a dataframe\n",
        "\n",
        "TrainCols = list(trainData.columns.values)\n",
        "TestCols = list(testData.columns.values)\n",
        "print(TrainCols)\n",
        "print(TestCols)\n",
        "\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['State', 'Account Length', 'Area Code', \"Int'l Plan\", 'VMail Plan', 'VMail Message', 'Day Mins', 'Day Calls', 'Day Charge', 'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls', 'Night Charge', 'Intl Mins', 'Intl Calls', 'Intl Charge', 'CustServ Calls', 'TARGET']\n",
            "['State', 'Account Length', 'Area Code', \"Int'l Plan\", 'VMail Plan', 'VMail Message', 'Day Mins', 'Day Calls', 'Day Charge', 'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls', 'Night Charge', 'Intl Mins', 'Intl Calls', 'Intl Charge', 'CustServ Calls', 'TARGET']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8SooiqorkWI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "e459364e-de34-473b-b40a-26366220f176"
      },
      "source": [
        "#Do one Hot encoding for categorical features\n",
        "\n",
        "categoricalFeatures = [\"State\",\"Int'l Plan\",\"VMail Plan\"]\n",
        "combined_Data = pd.concat([trainData_Copy, testData_Copy], keys=[0,1])\n",
        "combined_Data = pd.get_dummies(combined_Data,columns=categoricalFeatures)\n",
        "\n",
        "\n",
        "print (combined_Data.shape)\n",
        "#Separate Train data and test data\n",
        "X_Train = combined_Data.xs(0)\n",
        "X_Test = combined_Data.xs(1)\n",
        "\n",
        "X_Test.head()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2426, 71)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Account Length</th>\n",
              "      <th>Area Code</th>\n",
              "      <th>VMail Message</th>\n",
              "      <th>Day Mins</th>\n",
              "      <th>Day Calls</th>\n",
              "      <th>Day Charge</th>\n",
              "      <th>Eve Mins</th>\n",
              "      <th>Eve Calls</th>\n",
              "      <th>Eve Charge</th>\n",
              "      <th>Night Mins</th>\n",
              "      <th>Night Calls</th>\n",
              "      <th>Night Charge</th>\n",
              "      <th>Intl Mins</th>\n",
              "      <th>Intl Calls</th>\n",
              "      <th>Intl Charge</th>\n",
              "      <th>CustServ Calls</th>\n",
              "      <th>State_AK</th>\n",
              "      <th>State_AL</th>\n",
              "      <th>State_AR</th>\n",
              "      <th>State_AZ</th>\n",
              "      <th>State_CA</th>\n",
              "      <th>State_CO</th>\n",
              "      <th>State_CT</th>\n",
              "      <th>State_DC</th>\n",
              "      <th>State_DE</th>\n",
              "      <th>State_FL</th>\n",
              "      <th>State_GA</th>\n",
              "      <th>State_HI</th>\n",
              "      <th>State_IA</th>\n",
              "      <th>State_ID</th>\n",
              "      <th>State_IL</th>\n",
              "      <th>State_IN</th>\n",
              "      <th>State_KS</th>\n",
              "      <th>State_KY</th>\n",
              "      <th>State_LA</th>\n",
              "      <th>State_MA</th>\n",
              "      <th>State_MD</th>\n",
              "      <th>State_ME</th>\n",
              "      <th>State_MI</th>\n",
              "      <th>State_MN</th>\n",
              "      <th>State_MO</th>\n",
              "      <th>State_MS</th>\n",
              "      <th>State_MT</th>\n",
              "      <th>State_NC</th>\n",
              "      <th>State_ND</th>\n",
              "      <th>State_NE</th>\n",
              "      <th>State_NH</th>\n",
              "      <th>State_NJ</th>\n",
              "      <th>State_NM</th>\n",
              "      <th>State_NV</th>\n",
              "      <th>State_NY</th>\n",
              "      <th>State_OH</th>\n",
              "      <th>State_OK</th>\n",
              "      <th>State_OR</th>\n",
              "      <th>State_PA</th>\n",
              "      <th>State_RI</th>\n",
              "      <th>State_SC</th>\n",
              "      <th>State_SD</th>\n",
              "      <th>State_TN</th>\n",
              "      <th>State_TX</th>\n",
              "      <th>State_UT</th>\n",
              "      <th>State_VA</th>\n",
              "      <th>State_VT</th>\n",
              "      <th>State_WA</th>\n",
              "      <th>State_WI</th>\n",
              "      <th>State_WV</th>\n",
              "      <th>State_WY</th>\n",
              "      <th>Int'l Plan_no</th>\n",
              "      <th>Int'l Plan_yes</th>\n",
              "      <th>VMail Plan_no</th>\n",
              "      <th>VMail Plan_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>415</td>\n",
              "      <td>26</td>\n",
              "      <td>307.1</td>\n",
              "      <td>94</td>\n",
              "      <td>52.21</td>\n",
              "      <td>289.4</td>\n",
              "      <td>78</td>\n",
              "      <td>24.60</td>\n",
              "      <td>174.9</td>\n",
              "      <td>109</td>\n",
              "      <td>7.87</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>118.2</td>\n",
              "      <td>106</td>\n",
              "      <td>20.09</td>\n",
              "      <td>167.2</td>\n",
              "      <td>136</td>\n",
              "      <td>14.21</td>\n",
              "      <td>214.2</td>\n",
              "      <td>106</td>\n",
              "      <td>9.64</td>\n",
              "      <td>12.2</td>\n",
              "      <td>3</td>\n",
              "      <td>3.29</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>130</td>\n",
              "      <td>510</td>\n",
              "      <td>0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>95</td>\n",
              "      <td>26.18</td>\n",
              "      <td>205.9</td>\n",
              "      <td>106</td>\n",
              "      <td>17.50</td>\n",
              "      <td>233.7</td>\n",
              "      <td>75</td>\n",
              "      <td>10.52</td>\n",
              "      <td>12.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3.48</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>143</td>\n",
              "      <td>408</td>\n",
              "      <td>0</td>\n",
              "      <td>155.5</td>\n",
              "      <td>101</td>\n",
              "      <td>26.44</td>\n",
              "      <td>213.4</td>\n",
              "      <td>89</td>\n",
              "      <td>18.14</td>\n",
              "      <td>237.9</td>\n",
              "      <td>61</td>\n",
              "      <td>10.71</td>\n",
              "      <td>7.6</td>\n",
              "      <td>11</td>\n",
              "      <td>2.05</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89</td>\n",
              "      <td>510</td>\n",
              "      <td>0</td>\n",
              "      <td>125.6</td>\n",
              "      <td>108</td>\n",
              "      <td>21.35</td>\n",
              "      <td>213.0</td>\n",
              "      <td>90</td>\n",
              "      <td>18.11</td>\n",
              "      <td>181.7</td>\n",
              "      <td>108</td>\n",
              "      <td>8.18</td>\n",
              "      <td>5.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1.46</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Account Length  Area Code  ...  VMail Plan_no  VMail Plan_yes\n",
              "0              50        415  ...              0               1\n",
              "1              72        415  ...              1               0\n",
              "2             130        510  ...              1               0\n",
              "3             143        408  ...              1               0\n",
              "4              89        510  ...              1               0\n",
              "\n",
              "[5 rows x 71 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwikuM4XrkY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e619c7-3a2c-4551-8ec4-5ecf67298055"
      },
      "source": [
        "# Initialising Decision Tree Algorithm and fitting the model on train set\n",
        "dt = DecisionTreeClassifier(max_leaf_nodes=50)\n",
        "dt.fit(X_Train, Y_Train)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=50,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtOYBMyNrkeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbca393-54f8-4281-8bb9-ab7a5c104f19"
      },
      "source": [
        "# For us to check accuracy of our algorithm, we need to predict that data set for which we have TARGET available. \n",
        "# Eg predict for Xtrain and check accuracy with TARGET that we have in order to judge our model.\n",
        "\n",
        "X_Pred = dt.predict(X_Test)\n",
        "#Model Accuracy\n",
        "print(\"Accuracy:\", metrics.accuracy_score(Y_Test,X_Pred))\n",
        "\n",
        "print(classification_report(Y_Test,X_Pred ))  \n",
        "\n",
        "dt_cv_score = cross_val_score(dt, X_Train, Y_Train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(dt_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Boosting: \",dt_cv_score.mean())\n",
        "\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.929421094369548\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96      1069\n",
            "           1       0.88      0.62      0.73       192\n",
            "\n",
            "    accuracy                           0.93      1261\n",
            "   macro avg       0.91      0.80      0.84      1261\n",
            "weighted avg       0.93      0.93      0.92      1261\n",
            "\n",
            "=== All AUC Scores ===\n",
            "[0.56372549 0.66928105 0.74771242 0.75915033 0.76732026 0.7780112\n",
            " 0.66701681 0.81337535 0.58473389 0.80462046]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Boosting:  0.7154947259431825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_erQ1QP4o3g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e840c2b5-4b23-46c4-eab4-a3db04af1217"
      },
      "source": [
        "#Plotting the decision Tree\n",
        "tree.plot_tree(dt)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(242.72412219101125, 209.6742857142857, 'X[15] <= 3.5\\ngini = 0.204\\nsamples = 815\\nvalue = [721, 94]'),\n",
              " Text(180.7426264044944, 194.14285714285714, 'X[3] <= 302.15\\ngini = 0.15\\nsamples = 749\\nvalue = [688, 61]'),\n",
              " Text(120.49508426966293, 178.61142857142858, 'X[67] <= 0.5\\ngini = 0.131\\nsamples = 738\\nvalue = [686, 52]'),\n",
              " Text(22.570786516853936, 163.07999999999998, 'X[14] <= 3.44\\ngini = 0.438\\nsamples = 71\\nvalue = [48, 23]'),\n",
              " Text(15.047191011235956, 147.54857142857142, 'X[13] <= 2.5\\ngini = 0.266\\nsamples = 57\\nvalue = [48, 9]'),\n",
              " Text(7.523595505617978, 132.01714285714286, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
              " Text(22.570786516853936, 132.01714285714286, 'X[4] <= 53.5\\ngini = 0.077\\nsamples = 50\\nvalue = [48, 2]'),\n",
              " Text(15.047191011235956, 116.48571428571428, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(30.094382022471912, 116.48571428571428, 'X[6] <= 324.85\\ngini = 0.04\\nsamples = 49\\nvalue = [48, 1]'),\n",
              " Text(22.570786516853936, 100.9542857142857, 'gini = 0.0\\nsamples = 47\\nvalue = [47, 0]'),\n",
              " Text(37.61797752808989, 100.9542857142857, 'X[23] <= 0.5\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
              " Text(30.094382022471912, 85.42285714285714, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(45.14157303370787, 85.42285714285714, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
              " Text(30.094382022471912, 147.54857142857142, 'gini = 0.0\\nsamples = 14\\nvalue = [0, 14]'),\n",
              " Text(218.41938202247192, 163.07999999999998, 'X[8] <= 27.75\\ngini = 0.083\\nsamples = 667\\nvalue = [638, 29]'),\n",
              " Text(186.67921348314607, 147.54857142857142, 'X[3] <= 226.15\\ngini = 0.075\\nsamples = 663\\nvalue = [637, 26]'),\n",
              " Text(145.76966292134833, 132.01714285714286, 'X[2] <= 47.0\\ngini = 0.036\\nsamples = 550\\nvalue = [540, 10]'),\n",
              " Text(118.49662921348315, 116.48571428571428, 'X[47] <= 0.5\\ngini = 0.032\\nsamples = 548\\nvalue = [539, 9]'),\n",
              " Text(86.52134831460674, 100.9542857142857, 'X[4] <= 124.5\\ngini = 0.026\\nsamples = 538\\nvalue = [531, 7]'),\n",
              " Text(60.188764044943824, 85.42285714285714, 'X[7] <= 145.0\\ngini = 0.012\\nsamples = 486\\nvalue = [483, 3]'),\n",
              " Text(45.14157303370787, 69.89142857142858, 'X[42] <= 0.5\\ngini = 0.008\\nsamples = 482\\nvalue = [480, 2]'),\n",
              " Text(37.61797752808989, 54.359999999999985, 'gini = 0.004\\nsamples = 472\\nvalue = [471, 1]'),\n",
              " Text(52.66516853932585, 54.359999999999985, 'X[8] <= 21.305\\ngini = 0.18\\nsamples = 10\\nvalue = [9, 1]'),\n",
              " Text(45.14157303370787, 38.82857142857142, 'gini = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
              " Text(60.188764044943824, 38.82857142857142, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(75.23595505617978, 69.89142857142858, 'X[7] <= 149.5\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
              " Text(67.7123595505618, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(82.75955056179775, 54.359999999999985, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
              " Text(112.85393258426967, 85.42285714285714, 'X[21] <= 0.5\\ngini = 0.142\\nsamples = 52\\nvalue = [48, 4]'),\n",
              " Text(105.3303370786517, 69.89142857142858, 'X[2] <= 40.5\\ngini = 0.111\\nsamples = 51\\nvalue = [48, 3]'),\n",
              " Text(97.80674157303372, 54.359999999999985, 'X[41] <= 0.5\\ngini = 0.077\\nsamples = 50\\nvalue = [48, 2]'),\n",
              " Text(90.28314606741574, 38.82857142857142, 'X[51] <= 0.5\\ngini = 0.04\\nsamples = 49\\nvalue = [48, 1]'),\n",
              " Text(82.75955056179775, 23.29714285714286, 'gini = 0.0\\nsamples = 45\\nvalue = [45, 0]'),\n",
              " Text(97.80674157303372, 23.29714285714286, 'X[12] <= 12.25\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
              " Text(90.28314606741574, 7.765714285714267, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
              " Text(105.3303370786517, 7.765714285714267, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(105.3303370786517, 38.82857142857142, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(112.85393258426967, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(120.37752808988765, 69.89142857142858, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(150.47191011235955, 100.9542857142857, 'X[14] <= 4.225\\ngini = 0.32\\nsamples = 10\\nvalue = [8, 2]'),\n",
              " Text(142.94831460674158, 85.42285714285714, 'X[10] <= 127.0\\ngini = 0.198\\nsamples = 9\\nvalue = [8, 1]'),\n",
              " Text(135.4247191011236, 69.89142857142858, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
              " Text(150.47191011235955, 69.89142857142858, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(157.99550561797753, 85.42285714285714, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(173.04269662921348, 116.48571428571428, 'X[12] <= 5.5\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
              " Text(165.5191011235955, 100.9542857142857, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
              " Text(180.56629213483149, 100.9542857142857, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(227.58876404494384, 132.01714285714286, 'X[6] <= 245.4\\ngini = 0.243\\nsamples = 113\\nvalue = [97, 16]'),\n",
              " Text(203.1370786516854, 116.48571428571428, 'X[36] <= 0.5\\ngini = 0.102\\nsamples = 93\\nvalue = [88, 5]'),\n",
              " Text(195.61348314606744, 100.9542857142857, 'X[0] <= 25.0\\ngini = 0.083\\nsamples = 92\\nvalue = [88, 4]'),\n",
              " Text(176.80449438202248, 85.42285714285714, 'X[4] <= 90.0\\ngini = 0.5\\nsamples = 4\\nvalue = [2, 2]'),\n",
              " Text(169.2808988764045, 69.89142857142858, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
              " Text(184.32808988764046, 69.89142857142858, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
              " Text(214.42247191011236, 85.42285714285714, 'X[5] <= 38.555\\ngini = 0.044\\nsamples = 88\\nvalue = [86, 2]'),\n",
              " Text(199.3752808988764, 69.89142857142858, 'X[6] <= 160.95\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
              " Text(191.85168539325844, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
              " Text(206.8988764044944, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(229.46966292134832, 69.89142857142858, 'X[17] <= 0.5\\ngini = 0.023\\nsamples = 86\\nvalue = [85, 1]'),\n",
              " Text(221.94606741573034, 54.359999999999985, 'gini = 0.0\\nsamples = 80\\nvalue = [80, 0]'),\n",
              " Text(236.9932584269663, 54.359999999999985, 'X[11] <= 11.565\\ngini = 0.278\\nsamples = 6\\nvalue = [5, 1]'),\n",
              " Text(229.46966292134832, 38.82857142857142, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
              " Text(244.5168539325843, 38.82857142857142, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(210.6606741573034, 100.9542857142857, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(252.04044943820227, 116.48571428571428, 'X[3] <= 234.2\\ngini = 0.495\\nsamples = 20\\nvalue = [9, 11]'),\n",
              " Text(236.9932584269663, 100.9542857142857, 'X[9] <= 255.65\\ngini = 0.245\\nsamples = 7\\nvalue = [6, 1]'),\n",
              " Text(229.46966292134832, 85.42285714285714, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
              " Text(244.5168539325843, 85.42285714285714, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(267.0876404494382, 100.9542857142857, 'X[69] <= 0.5\\ngini = 0.355\\nsamples = 13\\nvalue = [3, 10]'),\n",
              " Text(259.56404494382025, 85.42285714285714, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
              " Text(274.6112359550562, 85.42285714285714, 'X[10] <= 136.0\\ngini = 0.165\\nsamples = 11\\nvalue = [1, 10]'),\n",
              " Text(267.0876404494382, 69.89142857142858, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 10]'),\n",
              " Text(282.13483146067415, 69.89142857142858, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
              " Text(250.15955056179777, 147.54857142857142, 'X[10] <= 120.0\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
              " Text(242.6359550561798, 132.01714285714286, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
              " Text(257.68314606741575, 132.01714285714286, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
              " Text(240.99016853932585, 178.61142857142858, 'X[70] <= 0.5\\ngini = 0.298\\nsamples = 11\\nvalue = [2, 9]'),\n",
              " Text(233.46657303370787, 163.07999999999998, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 9]'),\n",
              " Text(248.51376404494383, 163.07999999999998, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
              " Text(304.7056179775281, 194.14285714285714, 'X[5] <= 22.975\\ngini = 0.5\\nsamples = 66\\nvalue = [33, 33]'),\n",
              " Text(289.65842696629215, 178.61142857142858, 'X[7] <= 79.0\\ngini = 0.142\\nsamples = 13\\nvalue = [1, 12]'),\n",
              " Text(282.13483146067415, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
              " Text(297.1820224719101, 163.07999999999998, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 12]'),\n",
              " Text(319.75280898876406, 178.61142857142858, 'X[4] <= 118.0\\ngini = 0.478\\nsamples = 53\\nvalue = [32, 21]'),\n",
              " Text(312.2292134831461, 163.07999999999998, 'X[6] <= 127.65\\ngini = 0.411\\nsamples = 45\\nvalue = [32, 13]'),\n",
              " Text(304.7056179775281, 147.54857142857142, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
              " Text(319.75280898876406, 147.54857142857142, 'X[3] <= 274.4\\ngini = 0.343\\nsamples = 41\\nvalue = [32, 9]'),\n",
              " Text(312.2292134831461, 132.01714285714286, 'X[5] <= 30.795\\ngini = 0.234\\nsamples = 37\\nvalue = [32, 5]'),\n",
              " Text(304.7056179775281, 116.48571428571428, 'X[11] <= 6.95\\ngini = 0.444\\nsamples = 15\\nvalue = [10, 5]'),\n",
              " Text(297.1820224719101, 100.9542857142857, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
              " Text(312.2292134831461, 100.9542857142857, 'X[8] <= 17.725\\ngini = 0.355\\nsamples = 13\\nvalue = [10, 3]'),\n",
              " Text(304.7056179775281, 85.42285714285714, 'X[11] <= 9.39\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
              " Text(297.1820224719101, 69.89142857142858, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
              " Text(312.2292134831461, 69.89142857142858, 'X[6] <= 194.05\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
              " Text(304.7056179775281, 54.359999999999985, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
              " Text(319.75280898876406, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
              " Text(319.75280898876406, 85.42285714285714, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
              " Text(319.75280898876406, 116.48571428571428, 'gini = 0.0\\nsamples = 22\\nvalue = [22, 0]'),\n",
              " Text(327.27640449438206, 132.01714285714286, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
              " Text(327.27640449438206, 163.07999999999998, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8]')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1fXRPrwpsHR",
        "outputId": "b735ceba-ded0-4cd3-c2a6-164ffc4665ea"
      },
      "source": [
        "rf = RandomForestClassifier(max_leaf_nodes=50)\n",
        "rf.fit(X_Train, Y_Train)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=50, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgLom2OWqkjH",
        "outputId": "90e9a6e0-f274-4c45-eac5-de8bb45a8839"
      },
      "source": [
        "X_Pred = rf.predict(X_Test)\n",
        "#Model Accuracy\n",
        "print(\"Accuracy:\", metrics.accuracy_score(Y_Test,X_Pred))\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "print(classification_report(Y_Test,X_Pred ))  \n",
        "\n",
        "rf_cv_score = cross_val_score(rf, X_Train, Y_Train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(rf_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Boosting: \",rf_cv_score.mean())\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8826328310864393\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94      1069\n",
            "           1       0.96      0.24      0.38       192\n",
            "\n",
            "    accuracy                           0.88      1261\n",
            "   macro avg       0.92      0.62      0.66      1261\n",
            "weighted avg       0.89      0.88      0.85      1261\n",
            "\n",
            "=== All AUC Scores ===\n",
            "[0.84575163 0.92745098 0.90326797 0.82026144 0.91830065 0.92787115\n",
            " 0.98039216 0.86414566 0.92507003 0.85742574]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Boosting:  0.8969937413909458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2taSPrRUq7Xe",
        "outputId": "97fb8aba-36c1-43a1-cc28-11ba1aec9e6f"
      },
      "source": [
        "gb =GradientBoostingClassifier()\n",
        "gb.fit(X_Train, Y_Train)\n",
        "gb_predict=gb.predict(X_Test)\n",
        "\n",
        "X_Pred = gb.predict(X_Test)\n",
        "#Model Accuracy\n",
        "print(\"Accuracy:\", metrics.accuracy_score(Y_Test,X_Pred))\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "print(classification_report(Y_Test,X_Pred ))  \n",
        "\n",
        "gb_cv_score = cross_val_score(gb, X_Train, Y_Train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(gb_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Boosting: \",gb_cv_score.mean())\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9278350515463918\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96      1069\n",
            "           1       0.90      0.59      0.71       192\n",
            "\n",
            "    accuracy                           0.93      1261\n",
            "   macro avg       0.92      0.79      0.84      1261\n",
            "weighted avg       0.93      0.93      0.92      1261\n",
            "\n",
            "=== All AUC Scores ===\n",
            "[0.86666667 0.95555556 0.91633987 0.83921569 0.94444444 0.93347339\n",
            " 0.97058824 0.86764706 0.96428571 0.8349835 ]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Boosting:  0.9093200118331162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9NHnvpErwg9",
        "outputId": "75653874-87fe-4087-eec5-00e7795777ed"
      },
      "source": [
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_Train, Y_Train)\n",
        "\n",
        "X_Pred = mlp.predict(X_Test)\n",
        "#Model Accuracy\n",
        "print(\"Accuracy:\", metrics.accuracy_score(Y_Test,X_Pred))\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "print(classification_report(Y_Test,X_Pred ))  \n",
        "\n",
        "mlp_cv_score = cross_val_score(mlp, X_Train, Y_Train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(mlp_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Boosting: \",mlp_cv_score.mean())\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8080888183980968\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88      1069\n",
            "           1       0.41      0.60      0.49       192\n",
            "\n",
            "    accuracy                           0.81      1261\n",
            "   macro avg       0.67      0.72      0.69      1261\n",
            "weighted avg       0.84      0.81      0.82      1261\n",
            "\n",
            "=== All AUC Scores ===\n",
            "[0.6627451  0.7496732  0.76078431 0.67189542 0.84248366 0.75070028\n",
            " 0.89915966 0.78851541 0.82072829 0.78745875]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Boosting:  0.7734144086677575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpgJH0p5suYf",
        "outputId": "68a35cea-2890-4b05-ce81-8ee1cc9afd57"
      },
      "source": [
        "#SMOTE\n",
        "print(\"___________________________________________________________________\\nSMOTE\\n\")\n",
        "print('Original dataset shape %s' % Counter(Y_Train))\n",
        "sm = SMOTE(sampling_strategy='float', ratio=0.5)\n",
        "X_res, y_res = sm.fit_resample(X_Train, Y_Train)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "___________________________________________________________________\n",
            "SMOTE\n",
            "\n",
            "Original dataset shape Counter({0: 1019, 1: 146})\n",
            "Resampled dataset shape Counter({0: 1019, 1: 509})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kQHmmVDuQBZ",
        "outputId": "e077e065-9664-42d0-ad6d-27f415db175f"
      },
      "source": [
        "models = [ DecisionTreeClassifier(),GradientBoostingClassifier(), MLPClassifier()]\n",
        "      \n",
        "S_Train, S_Test = stacking(models,                   \n",
        "                           X_res, y_res, X_test,   \n",
        "                           regression=False, \n",
        "     \n",
        "                           mode='oof_pred_bag', \n",
        "       \n",
        "                           needs_proba=False,\n",
        "         \n",
        "                           save_dir=None, \n",
        "            \n",
        "                           metric=accuracy_score, \n",
        "    \n",
        "                           n_folds=4, \n",
        "                 \n",
        "                           stratified=True,\n",
        "            \n",
        "                           shuffle=True,  \n",
        "            \n",
        "                           random_state=0,    \n",
        "         \n",
        "                           verbose=2)\n",
        "\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [DecisionTreeClassifier]\n",
            "    fold  0:  [0.87696335]\n",
            "    fold  1:  [0.89528796]\n",
            "    fold  2:  [0.92408377]\n",
            "    fold  3:  [0.91884817]\n",
            "    ----\n",
            "    MEAN:     [0.90379581] + [0.01891123]\n",
            "    FULL:     [0.90379581]\n",
            "\n",
            "model  1:     [GradientBoostingClassifier]\n",
            "    fold  0:  [0.92931937]\n",
            "    fold  1:  [0.94764398]\n",
            "    fold  2:  [0.92931937]\n",
            "    fold  3:  [0.94502618]\n",
            "    ----\n",
            "    MEAN:     [0.93782723] + [0.00855805]\n",
            "    FULL:     [0.93782723]\n",
            "\n",
            "model  2:     [MLPClassifier]\n",
            "    fold  0:  [0.82984293]\n",
            "    fold  1:  [0.82984293]\n",
            "    fold  2:  [0.73560209]\n",
            "    fold  3:  [0.83507853]\n",
            "    ----\n",
            "    MEAN:     [0.80759162] + [0.04161810]\n",
            "    FULL:     [0.80759162]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PMQLWuQueQ-"
      },
      "source": [
        "# In[10]:\n",
        "#STACKING - CONTRUCT A RF Model==============================\n",
        "model = RandomForestClassifier()\n",
        "    \n",
        "model = model.fit(S_Train, y_res)\n",
        "y_pred = model.predict(S_Test)\n"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGjPetH9_9HX",
        "outputId": "941ca03b-0347-4bf7-807b-70eac0007f85"
      },
      "source": [
        "#Model Accuracy\n",
        "print(\"Accuracy:\", metrics.accuracy_score(Y_test,y_pred))\n",
        "\n",
        "print(classification_report(Y_test,y_pred ))  \n",
        "\n",
        "m_cv_score = cross_val_score(model, S_Train, y_res, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(m_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Boosting: \",m_cv_score.mean())\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9828571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       298\n",
            "           1       1.00      0.88      0.94        52\n",
            "\n",
            "    accuracy                           0.98       350\n",
            "   macro avg       0.99      0.94      0.96       350\n",
            "weighted avg       0.98      0.98      0.98       350\n",
            "\n",
            "=== All AUC Scores ===\n",
            "[0.9151288  0.91253364 0.88216071 0.97327951 0.96434064 0.97510573\n",
            " 0.97558631 0.985198   0.95539216 0.98689575]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Boosting:  0.9525621238594448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrCJo5gJvaOA",
        "outputId": "c68fa7fe-adc5-4c07-e188-74ea079afb34"
      },
      "source": [
        "#Hyper Parameter Tuning\n",
        "\n",
        "parameters={ 'n_estimators': range(50,150,20),'min_samples_split' : range(10,100,10),'max_depth': range(1,20,2)}\n",
        "rfc_random = RandomizedSearchCV(model,parameters,n_iter=15)\n",
        "rfc_random.fit(S_Train, y_res)\n",
        "grid_parm_rfc=rfc_random.best_params_\n",
        "print(grid_parm_rfc)\n",
        "\n",
        "#contruct random forest using the best parameters\n",
        "rfc= RandomForestClassifier(**grid_parm_rfc)\n",
        "rfc.fit(S_Train,y_res)\n",
        "rfc_predict = rfc.predict(S_Test)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': 110, 'min_samples_split': 20, 'max_depth': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiS5bCzzwsiL",
        "outputId": "67f1dad7-cdfd-409b-b999-bf0d46c98c23"
      },
      "source": [
        "#Model Accuracy\n",
        "print(\"Accuracy:\", metrics.accuracy_score(Y_test,rfc_predict))\n",
        "\n",
        "print(classification_report(Y_test,rfc_predict ))  \n",
        "\n",
        "rfc_cv_score = cross_val_score(rfc, S_Train, y_res, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(rfc_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Boosting: \",rfc_cv_score.mean())\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9828571428571429\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       298\n",
            "           1       1.00      0.88      0.94        52\n",
            "\n",
            "    accuracy                           0.98       350\n",
            "   macro avg       0.99      0.94      0.96       350\n",
            "weighted avg       0.98      0.98      0.98       350\n",
            "\n",
            "=== All AUC Scores ===\n",
            "[0.9151288  0.91253364 0.88273741 0.97327951 0.96434064 0.97452903\n",
            " 0.97558631 0.985198   0.95539216 0.98689575]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Boosting:  0.9525621238594448\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}